# üéâ dbt Setup Checklist for Divvy Bikes Project - COMPLETED

This checklist documents the setup process that has been successfully completed for the Divvy Bikes data engineering project.

## ‚úÖ Phase 1: External Tables Setup (COMPLETED ‚úÖ)

### Step 1.1: Create Glue Catalog Tables
```bash
cd /c/workspace/divvybikes-share-success/dbt_divvy/setup
chmod +x create_glue_tables.sh
./create_glue_tables.sh
```
- [x] 3 Glue tables created successfully ‚úÖ

### Step 1.2: Create External Schema in Redshift
- [x] Open AWS Console ‚Üí Amazon Redshift ‚Üí Query editor v2 ‚úÖ
- [x] Connect to: `divvybikes-dev.864899839546.ap-southeast-2.redshift-serverless.amazonaws.com` ‚úÖ
- [x] Database: `divvy` ‚úÖ
- [x] Open file: `setup/debug_external_schema.sql` ‚úÖ
- [x] Copy and paste all SQL content ‚úÖ
- [x] Execute - should show 3 tables: divvy_trips, weather_data, gbfs_stations ‚úÖ

### Step 1.3: Comprehensive Bronze Layer Setup
**STREAMLINED**: Single script handles table creation, correct formats, and partitioning
- [x] In Redshift Query Editor, open file: `setup/add_all_partitions.sql` ‚úÖ
- [x] Copy and paste all SQL content (comprehensive setup: drops/recreates/partitions) ‚úÖ
- [x] Execute - creates tables with correct file formats and adds 75 partitions (24 trips + 48 weather + 3 GBFS) ‚úÖ
- [x] Verify all verification queries return data counts:
  - divvy_trips_2023: ~190,301 rows ‚úÖ
  - divvy_trips_2024: ~144,873 rows ‚úÖ  
  - weather data: ~31 rows per location/month ‚úÖ
  - gbfs_stations: Station records for 2025 ‚úÖ

### Step 1.4: Verify Data Access
The comprehensive script includes verification queries that should show:
- [x] Sample 2023 trip data ‚úÖ
- [x] Sample 2024 trip data ‚úÖ
- [x] Weather data for Chicago and Evanston ‚úÖ
- [x] GBFS station information ‚úÖ

---

## ‚úÖ Phase 2: dbt Configuration (COMPLETED ‚úÖ)

### Step 2.1: Verify dbt Connection
```bash
cd /c/workspace/divvybikes-share-success/dbt_divvy
dbt debug
```
- [x] Connection successful ‚úÖ

### Step 2.2: Install Dependencies
```bash
dbt deps
```
- [x] Packages installed ‚úÖ

### Step 2.3: Test Source Access
```bash
dbt source freshness
```
- [x] Sources accessible ‚úÖ

---

## ‚úÖ Phase 3: Run dbt Pipeline (COMPLETED ‚úÖ)

### ‚úÖ Executed: Automated Pipeline 
```bash
./run_dbt_pipeline.sh
```

**Results Achieved:**
- [x] **Silver schema**: `trips_cleaned`, `weather_cleaned`, `stations_cleaned` tables ‚úÖ
- [x] **Gold schema**: `trips_enhanced`, `station_performance`, `behavioral_analysis` tables ‚úÖ  
- [x] **Marts schema**: `conversion_opportunities` view ‚úÖ
- [x] **Test Success**: 97% success rate (33/34 tests passed) ‚úÖ
- [x] **Documentation**: Generated and available at http://localhost:8080 ‚úÖ

---

## ‚úÖ Success Indicators (ALL ACHIEVED ‚úÖ)

After successful completion, we achieved:

- [x] **8 dbt models deployed** across Bronze ‚Üí Silver ‚Üí Gold ‚Üí Marts ‚úÖ
- [x] **335,174+ trip records processed** successfully ‚úÖ
- [x] **97% test success rate** (33/34 tests passed) ‚úÖ
- [x] **Comprehensive documentation** with data lineage visualization ‚úÖ
- [x] **Business intelligence views** for conversion analysis ‚úÖ
- [x] **GitHub Pages deployment** for public documentation access ‚úÖ

---

## üìä Final Project Statistics

### Data Processing
- **Total Records**: 335,174+ Chicago bike-share trips (2023-2024)
- **Data Sources**: Divvy trips, Weather API, GBFS stations
- **Transformation Layers**: 4 (Bronze ‚Üí Silver ‚Üí Gold ‚Üí Marts)

### Model Architecture
- **Bronze Layer**: 3 external tables via Redshift Spectrum
- **Silver Layer**: 3 cleaned and standardized models
- **Gold Layer**: 3 enhanced models with business logic
- **Marts Layer**: 1 conversion analysis view

### Quality Assurance
- **Tests Implemented**: 34 comprehensive data quality tests
- **Tests Passing**: 33/34 (97% success rate)
- **Coverage Areas**: Data integrity, business logic, coordinate validation

### Business Outcomes
- **Behavioral Analysis**: Member vs casual usage patterns identified
- **Revenue Impact**: Comprehensive pricing model with tax calculations
- **Conversion Opportunities**: Station-level scoring for marketing campaigns
- **Documentation**: Professional data lineage and model relationships

## üö® Troubleshooting Common Issues

### Issue: "External table not found"
**Solution**: Complete Phase 1 - External Tables Setup

### Issue: "Spectrum Scan Error - invalid version number" on weather data
**Root Cause**: All Bronze layer tables had incorrect file formats:
- divvy_trips: CSV files (e.g., 202301-divvy-tripdata.csv) but defined as PARQUET
- weather_data: CSV files (e.g., weather_data_chicago_2024_09.csv) but defined as PARQUET  
- gbfs_stations: JSON files but defined as PARQUET

**Solution**: The streamlined `setup/add_all_partitions.sql` script now handles this automatically:
```sql
-- Script includes comprehensive table creation with correct formats:
-- divvy_trips: CSV with ROW FORMAT DELIMITED, FIELDS TERMINATED BY ','
-- weather_data: CSV with ROW FORMAT DELIMITED, FIELDS TERMINATED BY ','  
-- gbfs_stations: JSON with ROW FORMAT SERDE 'org.openx.data.jsonserde.JsonSerDe'
```

**Alternative**: If tables already exist with wrong formats, run the script anyway - it includes DROP TABLE IF EXISTS statements to recreate them correctly.

### Issue: "Permission denied on S3"  
**Solution**: Verify IAM role `divvybikes-dev-redshift-role` has S3 access

### Issue: "AWS credentials invalid"
**Solution**: Test and fix AWS access
```bash
cd /c/workspace/divvybikes-share-success/dbt_divvy/setup
./test-aws-connection.sh
```
This script will:
- ‚úÖ Verify AWS credentials are valid
- ‚úÖ Test S3 bucket access permissions  
- ‚úÖ Show current AWS configuration
- ‚úÖ Provide specific troubleshooting guidance

### Issue: "dbt debug fails"
**Solution**: Check `~/.dbt/profiles.yml` configuration

### Issue: "No data in external tables"
**Solution**: Verify your Bronze layer S3 buckets contain parquet files

### Issue: "Tests failing"
**Solution**: Check data quality in Bronze layer, may need data cleaning

---

## üìû Quick Commands Reference

```bash
# TROUBLESHOOTING: Test AWS connectivity
cd /c/workspace/divvybikes-share-success/dbt_divvy/setup
./test-aws-connection.sh

# PHASE 1: External Tables Setup (one-time)
cd /c/workspace/divvybikes-share-success/dbt_divvy/setup
./create_glue_tables.sh
# Then run debug_external_schema.sql in Redshift Query Editor
# Then run add_all_partitions.sql in Redshift Query Editor

# PHASE 2: dbt Pipeline
cd /c/workspace/divvybikes-share-success/dbt_divvy
./run_dbt_pipeline.sh  

# Debug connection
dbt debug

# Test specific layer
dbt test --models tag:silver

# Generate docs
dbt docs generate && dbt docs serve --port 8080
```

---

**üéØ Goal**: Transform Bronze ‚Üí Silver ‚Üí Gold ‚Üí Marts for Divvy Bikes conversion analysis
**‚è±Ô∏è Estimated time**: 15-30 minutes for full setup and initial run
**üìö Documentation**: See `EXECUTION_GUIDE.md` for detailed commands
